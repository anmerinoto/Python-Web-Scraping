{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Web Scraping with Beautiful Soup: Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicación de cada import**\n",
    "\n",
    "**from bs4 import BeautifulSoup**\n",
    "- Trae la clase BeautifulSoup de la librería BeautifulSoup4.\n",
    "- Sirve para parsear (analizar) el HTML o XML de páginas web y poder extraer información (textos, tablas, enlaces, etc.).\n",
    "\n",
    "**from datetime import datetime**\n",
    "- Importa la clase datetime.\n",
    "- Te permite manejar fechas y horas: obtener la fecha actual, dar formato, calcular diferencias de tiempo, etc.\n",
    "\n",
    "**import requests**\n",
    "- Carga la librería requests, usada para hacer peticiones HTTP (GET, POST, etc.).\n",
    "- Es lo que se usa para descargar contenido de páginas web o conectarse a APIs.\n",
    "\n",
    "**import time**\n",
    "- Importa el módulo estándar time.\n",
    "- Te permite trabajar con funciones relacionadas al tiempo:\n",
    "\n",
    "        * time.sleep(segundos) para pausar la ejecución.\n",
    "        * time.time() para medir tiempos de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp')\n",
    "# Read the content of the server’s response\n",
    "src = req.text\n",
    "# Parse the response into an HTML tree\n",
    "soup = BeautifulSoup(src, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion**\n",
    "\n",
    "**req = requests.get('http://www.ilga.gov/senate/default.asp')**\n",
    "\n",
    "* Usa requests para hacer una petición HTTP GET a la página del Senado del Estado de Illinois (ilga.gov).\n",
    "* El servidor responde con el código HTML de esa página.\n",
    "* Ese resultado queda guardado en req.\n",
    "* Puedes verificar si la petición fue exitosa con req.status_code (200 significa OK).\n",
    "\n",
    "**src = req.text**\n",
    "* Extrae el contenido de la respuesta en forma de texto (string).\n",
    "* Aquí estará el HTML crudo de la página web.\n",
    "\n",
    "**soup = BeautifulSoup(src, 'lxml')**\n",
    "* Convierte el HTML en un árbol DOM navegable con la librería BeautifulSoup.\n",
    "* Usa el parser lxml (más rápido y flexible que html.parser).\n",
    "* Ahora puedes recorrer el HTML con métodos como .find(), .find_all(), .title, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Find All\n",
    "\n",
    "Use Beautiful Soup to find all the `a` elements with class `mainmenu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"a.mainmenu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del codigo**\n",
    "\n",
    "    Con soup.select(\"a.mainmenu\") obtendrás una lista de elementos <'a'> solo con clase mainmenu, es decir los dos primeros enlaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Extract Specific Attributes\n",
    "\n",
    "Extract all `href` attributes for each `mainmenu` URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[link['href'] for link in soup.select(\"a.mainmenu\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del codigo**\n",
    "\n",
    "    Ese código lista para extraer solo los atributos href (los enlaces) de todas las etiquetas <'a'> con clase mainmenu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Get `href` elements pointing to members' bills\n",
    "\n",
    "The code above retrieves information on:  \n",
    "\n",
    "- the senator's name,\n",
    "- their district number,\n",
    "- and their party.\n",
    "\n",
    "We now want to retrieve the URL for each senator's list of bills. Each URL will follow a specific format. \n",
    "\n",
    "The format for the list of bills for a given senator is:\n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID=[MEMBER_ID]&Primary=True`\n",
    "\n",
    "to get something like:\n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True`\n",
    "\n",
    "in which `MEMBER_ID=1911`. \n",
    "\n",
    "You should be able to see that, unfortunately, `MEMBER_ID` is not currently something pulled out in our scraping code.\n",
    "\n",
    "Your initial task is to modify the code above so that we also **retrieve the full URL which points to the corresponding page of primary-sponsored bills**, for each member, and return it along with their name, district, and party.\n",
    "\n",
    "Tips: \n",
    "\n",
    "* To do this, you will want to get the appropriate anchor element (`<a>`) in each legislator's row of the table. You can again use the `.select()` method on the `row` object in the loop to do this — similar to the command that finds all of the `td.detail` cells in the row. Remember that we only want the link to the legislator's bills, not the committees or the legislator's profile page.\n",
    "* The anchor elements' HTML will look like `<a href=\"/senate/Senator.asp/...\">Bills</a>`. The string in the `href` attribute contains the **relative** link we are after. You can access an attribute of a BeatifulSoup `Tag` object the same way you access a Python dictionary: `anchor['attributeName']`. See the <a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\">documentation</a> for more details.\n",
    "* There are a _lot_ of different ways to use BeautifulSoup to get things done. whatever you need to do to pull the `href` out is fine.\n",
    "\n",
    "The code has been partially filled out for you. Fill it in where it says `#YOUR CODE HERE`. Save the path into an object called `full_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
    "# Read the content of the server’s response\n",
    "src = req.text\n",
    "# Soup it\n",
    "soup = BeautifulSoup(src, \"lxml\")\n",
    "# Create empty list to store our data\n",
    "members = []\n",
    "\n",
    "# Returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "# Get rid of junk rows\n",
    "rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "# Loop through all rows\n",
    "for row in rows:\n",
    "    # Select only those 'td' tags with class 'detail'\n",
    "    detail_cells = row.select('td.detail') \n",
    "    # Keep only the text in each of those cells\n",
    "    row_data = [cell.text for cell in detail_cells]\n",
    "    # Collect information\n",
    "    name = row_data[0]\n",
    "    district = int(row_data[3])\n",
    "    party = row_data[4]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Extract href\n",
    "    href = row.select('a')[1]['href']\n",
    "    # Create full path\n",
    "    full_path = \"http://www.ilga.gov/senate/\" + href + \"&Primary=True\"\n",
    "    \n",
    "    # Store in a tuple\n",
    "    senator = (name, district, party, full_path)\n",
    "    # Append to list\n",
    "    members.append(senator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ese bloque de código es un scraper de la página del Senado de Illinois (98ª Asamblea General). Lo que hace es recorrer la tabla de senadores y extraer sus datos principales. Construye una lista de senadores de Illinois (98th GA) con:\n",
    "\n",
    "* Nombre\n",
    "* Distrito\n",
    "* Partido político\n",
    "* Enlace a su perfil oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] No se pudo leer https://www.ilga.gov/Senate/List: 404 Client Error: Not Found for url: https://www.ilga.gov/Senate/List\n",
      "Perfiles encontrados en la lista: 60\n",
      "Total miembros parseados: 60\n",
      "('Member', 8505, 'D', 'https://www.ilga.gov/Senate/Members/Details/3264')\n",
      "('Member', 5413, 'R', 'https://www.ilga.gov/Senate/Members/Details/3265')\n",
      "('Member', 8176, 'D', 'https://www.ilga.gov/Senate/Members/Details/3268')\n",
      "('Member', 5966, 'D', 'https://www.ilga.gov/Senate/Members/Details/3269')\n",
      "('Member', 422, 'D', 'https://www.ilga.gov/Senate/Members/Details/3270')\n",
      "('Member', 8250, 'D', 'https://www.ilga.gov/Senate/Members/Details/3271')\n",
      "('Member', 9573, 'D', 'https://www.ilga.gov/Senate/Members/Details/3276')\n",
      "('Member', 3840, 'R', 'https://www.ilga.gov/Senate/Members/Details/3281')\n",
      "('Member', 5145, 'D', 'https://www.ilga.gov/Senate/Members/Details/3291')\n",
      "('Member', 8066, 'D', 'https://www.ilga.gov/Senate/Members/Details/3292')\n",
      "\n",
      "Primeras 5 filas:\n",
      "   Nombre  Distrito Partido                                            Perfil\n",
      "0  Member      8505       D  https://www.ilga.gov/Senate/Members/Details/3264\n",
      "1  Member      5413       R  https://www.ilga.gov/Senate/Members/Details/3265\n",
      "2  Member      8176       D  https://www.ilga.gov/Senate/Members/Details/3268\n",
      "3  Member      5966       D  https://www.ilga.gov/Senate/Members/Details/3269\n",
      "4  Member       422       D  https://www.ilga.gov/Senate/Members/Details/3270\n",
      "\n",
      "CSV generado: senado_ilga_moderno.csv\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "LIST_URLS = [\n",
    "    \"https://www.ilga.gov/Senate/Members/List\",\n",
    "    \"https://www.ilga.gov/Senate/List\",\n",
    "]\n",
    "BASE = \"https://www.ilga.gov\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"es-ES,es;q=0.9,en;q=0.8\",\n",
    "    \"Referer\": \"https://www.ilga.gov/\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "def fetch(url):\n",
    "    s = requests.Session()\n",
    "    s.headers.update(HEADERS)\n",
    "    r = s.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r\n",
    "\n",
    "def find_profile_links(html, base=BASE):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    # busca anchors a /Senate/Members/Details/... (insensible a mayúsculas)\n",
    "    links = set()\n",
    "    for a in soup.select('a[href]'):\n",
    "        href = a.get(\"href\") or \"\"\n",
    "        if re.search(r\"/Senate/Members/Details/\\d+\", href, flags=re.I):\n",
    "            links.add(urljoin(base, href))\n",
    "    return sorted(links)\n",
    "\n",
    "def parse_profile(html):\n",
    "    \"\"\"Devuelve (name, district:int|None, party:str|''), usando varias heurísticas.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # Nombre: probar h1, h2, title, aria-labels…\n",
    "    name = \"\"\n",
    "    cand = []\n",
    "    cand += [h.get_text(strip=True) for h in soup.select(\"h1\")]\n",
    "    if not cand: cand += [h.get_text(strip=True) for h in soup.select(\"h2\")]\n",
    "    if not cand and soup.title: cand += [soup.title.get_text(strip=True)]\n",
    "    if cand: name = cand[0]\n",
    "\n",
    "    # Texto visible para regex\n",
    "    text = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    # Distrito (varias variantes)\n",
    "    district = None\n",
    "    for pat in [\n",
    "        r\"District\\s*(\\d+)\",\n",
    "        r\"(\\d+)\\s+District\",\n",
    "        r\"Senate\\s+District\\s*(\\d+)\",\n",
    "        r\"(\\d+)\\s+\\(D\\)|(\\d+)\\s+\\(R\\)|(\\d+)\\s+\\(I\\)\"\n",
    "    ]:\n",
    "        m = re.search(pat, text, flags=re.I)\n",
    "        if m:\n",
    "            # toma el primer grupo no vacío\n",
    "            for g in m.groups():\n",
    "                if g and g.isdigit():\n",
    "                    district = int(g)\n",
    "                    break\n",
    "        if district is not None:\n",
    "            break\n",
    "\n",
    "    # Partido (D/R/I o completo)\n",
    "    party = \"\"\n",
    "    # primero letra entre paréntesis\n",
    "    m = re.search(r\"\\((D|R|I)\\)\", text)\n",
    "    if m:\n",
    "        party = m.group(1)\n",
    "    else:\n",
    "        # palabras completas\n",
    "        if re.search(r\"\\bDemocrat(ic)?\\b\", text, flags=re.I):\n",
    "            party = \"D\"\n",
    "        elif re.search(r\"\\bRepublican\\b\", text, flags=re.I):\n",
    "            party = \"R\"\n",
    "        elif re.search(r\"\\bIndependent\\b\", text, flags=re.I):\n",
    "            party = \"I\"\n",
    "\n",
    "    return name, district, party\n",
    "\n",
    "# === Flujo principal ===\n",
    "try:\n",
    "    # 1) Prueba con las URLs de lista y junta todos los perfiles\n",
    "    all_profiles = []\n",
    "    for url in LIST_URLS:\n",
    "        try:\n",
    "            r = fetch(url)\n",
    "            profs = find_profile_links(r.text)\n",
    "            if profs:\n",
    "                all_profiles.extend(profs)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] No se pudo leer {url}: {e}\")\n",
    "\n",
    "    # de-duplicar\n",
    "    all_profiles = sorted(set(all_profiles))\n",
    "    print(\"Perfiles encontrados en la lista:\", len(all_profiles))\n",
    "\n",
    "    # Diagnóstico si no hay enlaces\n",
    "    if not all_profiles:\n",
    "        print(\"No se hallaron enlaces a perfiles. Guardando debug_list.html…\")\n",
    "        try:\n",
    "            open(\"debug_list.html\", \"w\", encoding=\"utf-8\").write(r.text)\n",
    "            print(\"Revisa debug_list.html para ver el HTML real (¿portal cautivo/bloqueo?).\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) Visita cada perfil y extrae datos\n",
    "    members = []\n",
    "    for i, purl in enumerate(all_profiles, 1):\n",
    "        try:\n",
    "            pr = fetch(purl)\n",
    "            name, district, party = parse_profile(pr.text)\n",
    "            if name:  # al menos nombre\n",
    "                members.append((name, district, party, purl))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Perfil con error ({purl}): {e}\")\n",
    "        time.sleep(0.5)  # pausa cortita para ser amable\n",
    "\n",
    "    print(\"Total miembros parseados:\", len(members))\n",
    "\n",
    "    # 3) Mostrar algunas filas\n",
    "    for m in members[:10]:\n",
    "        print(m)\n",
    "\n",
    "    # 4) (Opcional) DataFrame/CSV\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(members, columns=[\"Nombre\", \"Distrito\", \"Partido\", \"Perfil\"])\n",
    "        print(\"\\nPrimeras 5 filas:\")\n",
    "        print(df.head())\n",
    "        df.to_csv(\"senado_ilga_moderno.csv\", index=False, encoding=\"utf-8\")\n",
    "        print(\"\\nCSV generado: senado_ilga_moderno.csv\")\n",
    "    except ImportError:\n",
    "        print(\"Pandas no está instalado; omitiendo CSV. Instala con: pip install pandas openpyxl\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error general:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del codigo**\n",
    "\n",
    "Este script es un scraper a la pagina del Senado de Illinois (ILGA). Hace esto:\n",
    "\n",
    "**Configura**\n",
    "* LIST_URLS: páginas de listado donde buscar enlaces a perfiles.\n",
    "* HEADERS: cabeceras “de navegador” para evitar bloqueos simples.\n",
    "\n",
    "**Funciones clave**\n",
    "* fetch(url): hace GET con requests.Session + cabeceras y lanza error si no es 200.\n",
    "* find_profile_links(html): en el HTML del listado, busca todos los enlaces que coinciden con /Senate/Members/Details <'id'> y devuelve las URLs absolutas (evita dependencias del HTML antiguo).\n",
    "* parse_profile(html): abre cada perfil individual y, con heurísticas (regex):\n",
    "    * extrae name (buscando h1, h2 o <'title'>),\n",
    "    * detecta district (varios patrones: “District 47”, “47 District”, etc.),\n",
    "    * detecta party (letra entre paréntesis (D|R|I) o palabras “Democrat/Republican/Independent”).\n",
    "\n",
    "**Flujo principal**\n",
    "* Visita cada URL en LIST_URLS, junta y de-duplica todas las URLs de perfiles.\n",
    "* Si no encuentra enlaces, guarda debug_list.html para inspeccionar el HTML real (útil si hay portal cautivo/antibot).\n",
    "* Recorre cada perfil y arma members con tuplas (Nombre, Distrito, Partido, Perfil), poniendo una pausa de 0.5s por cortesía.\n",
    "* (Opcional) Crea un DataFrame y exporta senado_ilga_moderno.csv.\n",
    "\n",
    "**Salida**\n",
    "* Imprime cuántos **perfiles encontró** y **miembros parseados**, muestra los primeros, y guarda el CSV si pandas está instalado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Modularize Your Code\n",
    "\n",
    "Turn the code above into a function that accepts a URL, scrapes the URL for its senators, and returns a list of tuples containing information about each senator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_members(url):\n",
    "    # Make a GET request\n",
    "    req = requests.get(url)\n",
    "    # Read the content of the server’s response\n",
    "    src = req.text\n",
    "    # Soup it\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "    # Create empty list to store our data\n",
    "    members = []\n",
    "\n",
    "    # Returns every ‘tr tr tr’ css selector in the page\n",
    "    rows = soup.select('tr tr tr')\n",
    "    # Get rid of junk rows\n",
    "    rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "    # Loop through all rows\n",
    "    for row in rows:\n",
    "        # Select only those 'td' tags with class 'detail'\n",
    "        detail_cells = row.select('td.detail') \n",
    "        # Keep only the text in each of those cells\n",
    "        row_data = [cell.text for cell in detail_cells]\n",
    "        # Collect information\n",
    "        name = row_data[0]\n",
    "        district = int(row_data[3])\n",
    "        party = row_data[4]\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # Extract href\n",
    "        href = row.select('a')[1]['href']\n",
    "        # Create full path\n",
    "        full_path = \"https://www.ilga.gov/Senate/Members/List/\" + href + \"&Primary=True\"\n",
    "\n",
    "        # Store in a tuple\n",
    "        senator = (name, district, party, full_path)\n",
    "        # Append to list\n",
    "        members.append(senator)\n",
    "    return(members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del Codigo**\n",
    "\n",
    "Ese código define una función get_members(url) que hace un web scraping sobre una página de la Asamblea Legislativa de Illinois. Hace lo siguiente:\n",
    "\n",
    "**Descarga la página web**\n",
    "* Hace una petición HTTP a la URL.\n",
    "* Obtiene el HTML como texto.\n",
    "* Usa BeautifulSoup con el parser lxml para convertirlo en un árbol de etiquetas.\n",
    "\n",
    "**Inicializa una lista vacía**\n",
    "* Aquí se guardarán los senadores extraídos.\n",
    "\n",
    "**Busca filas de tabla**\n",
    "* Selecciona todas las filas <'tr'> anidadas tres niveles (muy específico).\n",
    "* Filtra solo las que contienen celdas <'td class=\"detail\">, que son las filas con información útil.\n",
    "\n",
    "**Extrae los datos de cada fila**\n",
    "* De cada fila toma solo las celdas con clase detail.\n",
    "* Convierte su contenido a texto.\n",
    "* Interpreta la primera celda como nombre, la cuarta como distrito (convertido a entero), y la quinta como partido político.\n",
    "\n",
    "**Obtiene el enlace al perfil**\n",
    "* Busca los enlaces <'a> dentro de la fila.\n",
    "* Toma el segundo enlace ([1]).\n",
    "* Construye una URL completa concatenando con una ruta base y agregando &Primary=True.\n",
    "\n",
    "**Guarda la información en una tupla**\n",
    "* Agrupa los datos en una tupla con la forma: (Nombre, Distrito, Partido, URL_perfil)\n",
    "* Lo agrega a la lista members.\n",
    "\n",
    "**Devuelve el resultado**\n",
    "* Retorna la lista completa de senadores encontrados en la página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_members(url: str = \"https://www.ilga.gov/Senate/Members/List\"):\n",
    "    \"\"\"\n",
    "    Devuelve una lista de tuplas (Nombre, Distrito:int, Partido:str, Perfil:str)\n",
    "    extraídas desde la página moderna del Senado de Illinois.\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "    members = []\n",
    "\n",
    "    # Enlaces a perfiles /Senate/Members/Details/<id>\n",
    "    for a in soup.select('a[href*=\"/Senate/Members/Details/\"], a[href*=\"/senate/members/details/\"]'):\n",
    "        name = a.get_text(strip=True)\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # En el contenedor suele venir \"Nombre 47 R\" (número + partido)\n",
    "        full_text = a.parent.get_text(\" \", strip=True)\n",
    "        tail = full_text.replace(name, \"\").strip()\n",
    "\n",
    "        # 1) patrón directo: \"47 R\"\n",
    "        m = re.search(r'(\\d+)\\s+([DRI])\\b', tail)\n",
    "        # 2) fallback: \"District 47 (R)\" u otras variantes\n",
    "        if not m:\n",
    "            m = re.search(r'(?:District\\s*)?(\\d+).*?([DRI])\\b', tail, re.I)\n",
    "        if not m:\n",
    "            # si no se detecta distrito/partido, igual guarda el nombre y el perfil\n",
    "            district, party = None, \"\"\n",
    "        else:\n",
    "            district = int(m.group(1))\n",
    "            party = m.group(2).upper()\n",
    "\n",
    "        profile = urljoin(url, a.get(\"href\"))\n",
    "        members.append((name, district, party, profile))\n",
    "\n",
    "    return members\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicación del Codigo**\n",
    "\n",
    "Ese código define una función get_members que hace web scraping sobre la página moderna del Senado de Illinois y devuelve información básica de cada senador. Hace lo siguiente:\n",
    "\n",
    "**Definicios de Imports**\n",
    "* re: para usar expresiones regulares.\n",
    "* urljoin: para construir URLs absolutas a partir de relativas.\n",
    "* requests: para hacer la descarga de la página web.\n",
    "* BeautifulSoup: para parsear el HTML.\n",
    "\n",
    "**Definición de la función**\n",
    "* Toma como parámetro opcional la URL del listado de miembros del Senado.\n",
    "* Si no le pasas nada, usa la lista oficial de senadores.\n",
    "\n",
    "**Descarga y parseo**\n",
    "* Descarga la página con un User-Agent “realista”.\n",
    "* raise_for_status() lanza error si la respuesta no fue 200 OK.\n",
    "* Convierte el HTML a un árbol con BeautifulSoup.\n",
    "\n",
    "**Inicializa lista de resultados**\n",
    "**Encuentra enlaces a perfiles individuales**\n",
    "* Busca todos los <'a> cuyo href contenga /Senate/Members/Details/.\n",
    "* Extrae el texto (nombre del senador).\n",
    "\n",
    "**Extrae distrito y partido del texto alrededor**\n",
    "* El contenedor donde está el link suele tener “Nombre 47 R”.\n",
    "* Usa regex para detectar el número de distrito y la letra del partido:\n",
    "    * D = Demócrata\n",
    "    * R = Republicano\n",
    "    * I = Independiente\n",
    "* Si no encuentra nada, pone district = None y party = \"\".\n",
    "\n",
    "**Construye la URL del perfil**\n",
    "* profile = urljoin(url, a.get(\"href\"))\n",
    "\n",
    "**Guarda la información**\n",
    "* members.append((name, district, party, profile))\n",
    "\n",
    "**Devuelve el resultado**\n",
    "* Entrega una lista de tuplas de la forma: (Nombre, Distrito, Partido, URL_perfil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total miembros: 60\n",
      "('Neil Anderson', None, '', 'https://www.ilga.gov/Senate/Members/Details/3312')\n",
      "('Omar Aquino', None, '', 'https://www.ilga.gov/Senate/Members/Details/3316')\n",
      "('Li Arellano, Jr.', None, '', 'https://www.ilga.gov/Senate/Members/Details/3383')\n",
      "('Chris Balkema', None, '', 'https://www.ilga.gov/Senate/Members/Details/3413')\n",
      "('Christopher Belt', None, '', 'https://www.ilga.gov/Senate/Members/Details/3337')\n"
     ]
    }
   ],
   "source": [
    "senate_members = get_members()  # o get_members(\"https://www.ilga.gov/Senate/Members/List\")\n",
    "print(\"Total miembros:\", len(senate_members))\n",
    "for m in senate_members[:5]:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Explicacion del Codigo**\n",
    "\n",
    "Este código ejecuta tu scraper, imprime el número total de senadores encontrados, y luego muestra en consola los primeros 5 registros (nombre, distrito, partido y link al perfil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Nombre Distrito Partido  \\\n",
      "0     Neil Anderson     None           \n",
      "1       Omar Aquino     None           \n",
      "2  Li Arellano, Jr.     None           \n",
      "3     Chris Balkema     None           \n",
      "4  Christopher Belt     None           \n",
      "\n",
      "                                             Perfil  \n",
      "0  https://www.ilga.gov/Senate/Members/Details/3312  \n",
      "1  https://www.ilga.gov/Senate/Members/Details/3316  \n",
      "2  https://www.ilga.gov/Senate/Members/Details/3383  \n",
      "3  https://www.ilga.gov/Senate/Members/Details/3413  \n",
      "4  https://www.ilga.gov/Senate/Members/Details/3337  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(senate_members, columns=[\"Nombre\", \"Distrito\", \"Partido\", \"Perfil\"])\n",
    "print(df.head())\n",
    "# df.to_csv(\"senado_ilga_moderno.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del Codigo**\n",
    "\n",
    "* Este código convierte tu lista de senadores en una tabla con pandas y te muestra las primeras 5 filas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-home Challenge: Writing a Scraper Function\n",
    "\n",
    "We want to scrape the webpages corresponding to bills sponsored by each bills.\n",
    "\n",
    "Write a function called `get_bills(url)` to parse a given bills URL. This will involve:\n",
    "\n",
    "  - requesting the URL using the <a href=\"http://docs.python-requests.org/en/latest/\">`requests`</a> library\n",
    "  - using the features of the `BeautifulSoup` library to find all of the `<td>` elements with the class `billlist`\n",
    "  - return a _list_ of tuples, each with:\n",
    "      - description (2nd column)\n",
    "      - chamber (S or H) (3rd column)\n",
    "      - the last action (4th column)\n",
    "      - the last action date (5th column)\n",
    "      \n",
    "This function has been partially completed. Fill in the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_members():\n",
    "    url = \"https://www.ilga.gov/Senate/Members/List\"\n",
    "    s = requests.Session(); s.headers.update(HEADERS)\n",
    "    r = s.get(url, timeout=30); r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Encuentra todos los enlaces a perfiles\n",
    "    profile_links = []\n",
    "    for a in soup.select('a[href]'):\n",
    "        href = a.get(\"href\") or \"\"\n",
    "        if re.search(r\"/Senate/Members/Details/\\d+\", href, flags=re.I):\n",
    "            profile_links.append(urljoin(url, href))\n",
    "    profile_links = sorted(set(profile_links))\n",
    "\n",
    "    members = []\n",
    "    # Si hay enlaces, visita cada perfil y extrae datos básicos\n",
    "    for purl in profile_links:\n",
    "        try:\n",
    "            pr = s.get(purl, timeout=30); pr.raise_for_status()\n",
    "            psoup = BeautifulSoup(pr.text, \"lxml\")\n",
    "            # Nombre\n",
    "            name = \"\"\n",
    "            if (h1 := psoup.select_one(\"h1\")): name = h1.get_text(strip=True)\n",
    "            elif (h2 := psoup.select_one(\"h2\")): name = h2.get_text(strip=True)\n",
    "            elif psoup.title: name = psoup.title.get_text(strip=True)\n",
    "\n",
    "            text = psoup.get_text(\" \", strip=True)\n",
    "            # Distrito\n",
    "            m = re.search(r\"District\\s*(\\d+)\", text, re.I) or re.search(r\"Senate\\s+District\\s*(\\d+)\", text, re.I)\n",
    "            district = int(m.group(1)) if m else None\n",
    "            # Partido\n",
    "            party = \"\"\n",
    "            m = re.search(r\"\\((D|R|I)\\)\", text)\n",
    "            if m: party = m.group(1)\n",
    "            elif re.search(r\"\\bDemocrat(ic)?\\b\", text, re.I): party = \"D\"\n",
    "            elif re.search(r\"\\bRepublican\\b\", text, re.I): party = \"R\"\n",
    "            elif re.search(r\"\\bIndependent\\b\", text, re.I): party = \"I\"\n",
    "\n",
    "            if name:\n",
    "                members.append((name, district, party, purl))\n",
    "        except Exception:\n",
    "            continue\n",
    "        time.sleep(0.2)  # ser amable con el servidor\n",
    "    return members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del Codigo**\n",
    "\n",
    "* La función get_members() descarga el listado de senadores de Illinois, detecta los enlaces a cada perfil, entra en cada uno, y devuelve una lista con nombre, distrito, partido y URL de perfil de todos los miembros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfil seleccionado: https://www.ilga.gov/Senate/Members/Details/3264\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "senate_members = get_members()\n",
    "if not senate_members:\n",
    "    raise RuntimeError(\"No se obtuvieron senadores. Revisa debug_list.html y los selectores.\")\n",
    "\n",
    "# Ahora es seguro acceder al primero\n",
    "test_url = senate_members[0][3]\n",
    "print(\"Perfil seleccionado:\", test_url)\n",
    "\n",
    "# Solo llama get_bills si tienes una URL válida\n",
    "bills = get_bills(test_url)\n",
    "print(bills[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicacion del Codigo**\n",
    "\n",
    "Ese fragmento de código es un bloque de prueba que usa tu función get_members() (la que scrapea la web del Senado) y después llama a otra función get_bills() (seguramente hecha por ti para extraer proyectos de ley de un senador).\n",
    "\n",
    "Hace lo siguiente:\n",
    "* Usa get_members() para obtener senadores.\n",
    "* Se asegura de que haya resultados.\n",
    "* Selecciona el perfil del primer senador.\n",
    "* Llama a get_bills() sobre ese perfil.\n",
    "* Imprime los primeros 5 proyectos de ley de ese senador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Bills\n",
    "\n",
    "Finally, create a dictionary `bills_dict` which maps a district number (the key) onto a list of bills (the value) coming from that district. You can do this by looping over all of the senate members in `members_dict` and calling `get_bills()` for each of their associated bill URLs.\n",
    "\n",
    "**NOTE:** please call the function `time.sleep(1)` for each iteration of the loop, so that we don't destroy the state's web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bills_dict = {}  \n",
    "for member in senate_members[:5]:\n",
    "    bills_dict[member[1]] = get_bills(member[3])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clave encontrada: None\n",
      "No hay datos para distrito 52.\n"
     ]
    }
   ],
   "source": [
    "# Verificar claves\n",
    "for key in bills_dict.keys():\n",
    "    print(\"Clave encontrada:\", key)\n",
    "\n",
    "# Acceder de forma segura\n",
    "if 52 in bills_dict:\n",
    "    print(\"Número de proyectos para distrito 52:\", len(bills_dict[52]))\n",
    "else:\n",
    "    print(\"No hay datos para distrito 52.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves disponibles en bills_dict: [None]\n",
      "Total claves: 1\n",
      "No hay datos para el distrito 52.\n"
     ]
    }
   ],
   "source": [
    "print(\"Claves disponibles en bills_dict:\", list(bills_dict.keys()))\n",
    "print(\"Total claves:\", len(bills_dict))\n",
    "\n",
    "bills_52 = bills_dict.get(52) or bills_dict.get(\"52\")\n",
    "if bills_52 is None:\n",
    "    print(\"No hay datos para el distrito 52.\")\n",
    "else:\n",
    "    print(\"Número de proyectos:\", len(bills_52))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
